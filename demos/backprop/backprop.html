<body>
<script src="../../dist/demo-util.js"></script>
<script src="../../dist/tensor.js"></script>

<style type="text/css">
    body {
        font-family: sans-serif;
    }
</style>

<h1>WebGL Backpropagation</h1>
<p>This page implements the backpropagation algorithm for training an artificial neural network.</p>



<script>
var gl = KV.createGL(),
	OutputTensor = KV.OutputTensor,
	Tensor = KV.Tensor,
	InPlaceTensor = KV.InPlaceTensor,
	TP = s => (out, opt) => KV.Run(s.join(''), out, opt);


// computes output = sigmoid(inputs * weights)
const ForwardLayer = TP`
    uniform Tensor inputs;
    uniform Tensor weights;
    
    vec4 sigmoid(vec4 x){
        return vec4(1, 1, 1, 1) / (vec4(1, 1, 1, 1) + exp(-x));
    }

    vec4 process4(ivec4 pos) {
        vec4 sum = vec4(0, 0, 0, 0);
        for(int k = 0; k < #(inputs.shape).y; k++){
            sum += inputs.read4(ivec4(pos.x, k, 0, 0))
                 * weights.read4(ivec4(k, pos.y, 0, 0));
        }
        return sigmoid(sum);
    }
`;

// computes difference = a - b
const Subtraction = TP`
    uniform Tensor a;
    uniform Tensor b;
    
    vec4 process4(ivec4 pos) {
        return a.read4(pos) - b.read4(pos);
    }
`;


// computes delta = error .* dsigmoid(outputs)
// where .* is elementwise product, aka hadamard

const BackwardLayer = TP`
    uniform Tensor error;
    uniform Tensor outputs;

    vec4 dsigmoid(vec4 x){
        return x * (vec4(1,1,1,1) - x);
    }
    
    vec4 process4(ivec4 pos) {
        return error.read4(pos)
             * dsigmoid(outputs.read4(pos));
    }
`;


// computes error = delta * weights^T
const IntermediateError = TP`
    uniform Tensor delta;
    uniform Tensor weights;
   
    vec4 process4(ivec4 pos) {
        vec4 sum = vec4(0, 0, 0, 0);
        for(int k = 0; k < #(delta.shape).y; k++){
            sum += delta.read4(ivec4(pos.x, k, 0, 0))
                 * weights.read4(ivec4(pos.y, k, 0, 0));
        }
        return sum;
    }
`;


// computes new weights = old weights + alpha * outputs^T * delta
const UpdateWeights = TP`
    uniform Tensor weights;
    uniform Tensor outputs;
    uniform Tensor delta;
    uniform float  alpha;

    vec4 process4(ivec4 pos) {
        vec4 sum = vec4(0, 0, 0, 0);
        for(int k = 0; k < #(outputs.shape).x; k++){
            sum += outputs.read4(ivec4(k, pos.x, 0, 0))
                 * delta.read4(ivec4(k, pos.y, 0, 0));
        }
        return weights.read4(pos) + alpha * sum;
    }
`;



X = new Tensor(gl, ndpack([[0,0,1],
            [0,1,1],
            [1,0,1],
            [1,1,1]]))
                
y = new Tensor(gl, ndpack([[0],
            [1],
            [1],
            [0]]))


syn0 = new InPlaceTensor(gl, ndpack([
    [-0.16595599,  0.44064899, -0.99977125, -0.39533485],
    [-0.70648822, -0.81532281, -0.62747958, -0.30887855],
    [-0.20646505,  0.07763347, -0.16161097,  0.370439  ]]))

syn1 = new InPlaceTensor(gl, ndpack([[-0.5910955 ],
       [ 0.75623487],
       [-0.94522481],
       [ 0.34093502]]))


l1 = new OutputTensor(gl, [4, 4])
l2 = new OutputTensor(gl, [4, 1])

l2_error = new OutputTensor(gl, [4, 1])
l2_delta = new OutputTensor(gl, [4, 1])
l1_error = new OutputTensor(gl, [4, 4])
l1_delta = new OutputTensor(gl, [4, 4])




for(var i = 0; i < 1000; i++){

    ForwardLayer(l1, { inputs: X, weights: syn0 })
    ForwardLayer(l2, { inputs: l1, weights: syn1 })
    Subtraction(l2_error, { a: y, b: l2 })

    if(i % 100 == 0){
        console.log("Error:", ndops.norm1(l2_error.read()) / l2_error.shape[0])    
    }

    BackwardLayer(l2_delta, { error: l2_error, outputs: l2 });
    IntermediateError(l1_error, { delta: l2_delta, weights: syn1 })
    BackwardLayer(l1_delta, { error: l1_error, outputs: l1 })
    UpdateWeights(syn1, { weights: syn1, outputs: l1, delta: l2_delta, alpha: 10 })
    UpdateWeights(syn0, { weights: syn0, outputs: X, delta: l1_delta, alpha: 10 })

}


console.log(syn1.print())
console.log(syn0.print())

syn0.show()

</script>